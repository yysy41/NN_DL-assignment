{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/5\n",
      "54000/54000 [==============================] - 41s 755us/sample - loss: 0.4072 - accuracy: 0.8886 - val_loss: 0.1097 - val_accuracy: 0.9708\n",
      "Epoch 2/5\n",
      "54000/54000 [==============================] - 44s 819us/sample - loss: 0.1107 - accuracy: 0.9670 - val_loss: 0.0668 - val_accuracy: 0.9812\n",
      "Epoch 3/5\n",
      "54000/54000 [==============================] - 43s 802us/sample - loss: 0.0754 - accuracy: 0.9773 - val_loss: 0.0657 - val_accuracy: 0.9805\n",
      "Epoch 4/5\n",
      "54000/54000 [==============================] - 43s 801us/sample - loss: 0.0577 - accuracy: 0.9829 - val_loss: 0.0480 - val_accuracy: 0.9865\n",
      "Epoch 5/5\n",
      "54000/54000 [==============================] - 43s 798us/sample - loss: 0.0478 - accuracy: 0.9848 - val_loss: 0.0459 - val_accuracy: 0.9868\n",
      "10000/10000 [==============================] - 2s 247us/sample - loss: 0.0380 - accuracy: 0.9867\n",
      "Test Accuracy: 0.9867\n"
     ]
    }
   ],
   "source": [
    "#将原来的代码改写成了适用tensorflow2.0版本的。\n",
    "\n",
    "\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds\n",
    "\n",
    "# # 超参数\n",
    "# learning_rate = 1e-4\n",
    "# keep_prob_rate = 0.7  # Dropout 比例\n",
    "# max_epoch = 2000\n",
    "# batch_size = 100\n",
    "\n",
    "# # 使用 tensorflow_datasets 加载 MNIST 数据集\n",
    "# mnist, info = tfds.load('mnist', with_info=True, as_supervised=True)\n",
    "\n",
    "# train_data, test_data = mnist['train'], mnist['test']\n",
    "\n",
    "# # 数据预处理：归一化并批处理\n",
    "# def preprocess(image, label):\n",
    "#     image = tf.cast(image, tf.float32) / 255.0  # 归一化\n",
    "#     return image, label\n",
    "\n",
    "# train_data = train_data.map(preprocess).batch(batch_size)\n",
    "# test_data = test_data.map(preprocess).batch(batch_size)\n",
    "\n",
    "# # 定义模型\n",
    "# class CNNModel(tf.keras.Model):\n",
    "#     def __init__(self):\n",
    "#         super(CNNModel, self).__init__()\n",
    "#         self.conv1 = tf.keras.layers.Conv2D(32, 7, activation='relu', padding='same')\n",
    "#         self.pool1 = tf.keras.layers.MaxPooling2D(2)\n",
    "#         self.conv2 = tf.keras.layers.Conv2D(64, 5, activation='relu', padding='same')\n",
    "#         self.pool2 = tf.keras.layers.MaxPooling2D(2)\n",
    "#         self.fc1 = tf.keras.layers.Dense(1024, activation='relu')\n",
    "#         self.dropout = tf.keras.layers.Dropout(keep_prob_rate)\n",
    "#         self.fc2 = tf.keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "#     def call(self, inputs, training=False):\n",
    "#         x = self.conv1(inputs)\n",
    "#         x = self.pool1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.pool2(x)\n",
    "#         x = tf.reshape(x, [-1, 7 * 7 * 64])  # Flattening\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.dropout(x, training=training)\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n",
    "# # 计算准确度\n",
    "# def compute_accuracy(v_xs, v_ys, cnn):\n",
    "#     y_pre = cnn(v_xs, training=False)\n",
    "#     correct_prediction = tf.equal(tf.argmax(y_pre, 1), tf.argmax(v_ys, 1))\n",
    "#     accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "#     return accuracy\n",
    "\n",
    "# # 启动训练\n",
    "# def train(cnn):\n",
    "#     optimizer = tf.optimizers.Adam(learning_rate)\n",
    "#     loss_func = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    \n",
    "#     for epoch in range(max_epoch):\n",
    "#         for step, (batch_xs, batch_ys) in enumerate(train_data):\n",
    "#             with tf.GradientTape() as tape:\n",
    "#                 output = cnn(batch_xs, training=True)  # Forward pass\n",
    "#                 loss = loss_func(batch_ys, output)  # Calculate loss\n",
    "            \n",
    "#             grads = tape.gradient(loss, cnn.trainable_variables)\n",
    "#             optimizer.apply_gradients(zip(grads, cnn.trainable_variables))\n",
    "            \n",
    "#             if step % 100 == 0:\n",
    "#                 accuracy = compute_accuracy(batch_xs, batch_ys, cnn)\n",
    "#                 print(f\"Epoch {epoch}/{max_epoch}, Step {step}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# # 测试模型\n",
    "# def test(cnn):\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     for batch_x, batch_y in test_data:\n",
    "#         y_pre = cnn(batch_x, training=False)\n",
    "#         _, pre_index = tf.math.top_k(y_pre, 1)\n",
    "#         pre_index = pre_index.numpy().flatten()\n",
    "#         correct += np.sum(pre_index == batch_y.numpy())\n",
    "#         total += batch_y.shape[0]\n",
    "#     return correct / total\n",
    "\n",
    "# # 创建模型并开始训练\n",
    "# cnn = CNNModel()\n",
    "# train(cnn)\n",
    "\n",
    "# # 测试模型\n",
    "# accuracy = test(cnn)\n",
    "# print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# 创建模型\n",
    "cnn_model = models.Sequential([\n",
    "    layers.Conv2D(32, (7, 7), activation='relu', padding='same', input_shape=(28, 28, 1)),  # 第一层卷积\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),  # 池化层\n",
    "    layers.Conv2D(64, (5, 5), activation='relu', padding='same'),  # 第二层卷积\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),  # 池化层\n",
    "    layers.Flatten(),  # 将二维数据展平为一维\n",
    "    layers.Dense(1024, activation='relu'),  # 全连接层\n",
    "    layers.Dropout(0.3),  # Dropout 层\n",
    "    layers.Dense(10, activation='softmax')  # 输出层\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "cnn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# 加载 MNIST 数据集\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# 数据归一化并添加通道维度\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "train_images = train_images[..., tf.newaxis]  # 添加通道维度\n",
    "test_images = test_images[..., tf.newaxis]\n",
    "\n",
    "# 训练模型\n",
    "cnn_model.fit(train_images, train_labels, epochs=5, batch_size=100, validation_split=0.1)\n",
    "\n",
    "# 评估模型\n",
    "loss, accuracy = cnn_model.evaluate(test_images, test_labels)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "nn_dl",
   "language": "python",
   "name": "nn_dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
